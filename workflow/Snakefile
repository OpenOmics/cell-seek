# Python standard library
from os.path import join
from os import listdir
import os, sys, re, json

# 3rd party imports from pypi
from snakemake.workflow import workflow as wf_api
from snakemake.utils import R

# Local imports
from scripts.common import (
    allocated,
    provided,
    references,
    str_bool
)

#Global workflow variables
configfile: 'config.json'
tmpdir = config['options']['tmp_dir']
pipeline = config['options']['pipeline']
CELLRANGER = config['options']['cellranger']
inputs = config['options']['input']
samples  = list(set([re.sub("_S[0-9]+_L00[0-9]", "", i) for i in config['samples']]))
workpath = config['project']['workpath']
genome = config['options']['genome']
features = config['options']['features']       # Features files for cellranger (not used in all pipelines)
libraries = config['options']['libraries']     # Libraries files for cellranger (not used in all pipelines)
cmo_ref = config['options']['cmo_reference']     # CMO Reference files for cellranger (only used in multi pipeline)
cmo_sample = config['options']['cmo_sample']     # CMO Sample files for cellranger (only used in multi pipelines)
rename = config['options']['rename']            # File containing how to rename samples when running Cell Ranger analysis
exclude_introns = str_bool(                           # Use introns for pre mRNA,
    config['options']['exclude_introns']              # default: False
)
create_bam = str_bool(                           # Create BAM files during Cell Ranger analysis,
    config['options']['create_bam']              # default: False
)
aggr = config['options']['aggregate']
input_fastq = config['options']['input']
filter_file = config['options']['filter']	# Filter threshold file for QC analysis (not used in all pipelines)
METADATA_FILE = config['options']['metadata']	# Metadata file for QC analysis (not used in all pipelines)
if 'libraries' in config:
    lib_samples = list(config['libraries'].keys()) # Libraries file samples
pipeline_output = []


rename_dict = dict()
if rename != 'None':
    with open(rename) as f:
        tabs = [i.lower() for i in next(f).strip().split(',')]
        index_fastq = [i for i in range(len(tabs)) if 'fastq' in tabs[i]][0]
        index_sample = [i for i in range(len(tabs)) if 'sample' in tabs[i]][0]
        for line in f:
            line = line.strip().split(',')
            rename_dict[line[index_fastq]] = line[index_sample]
    samples = list((set(samples) - set(rename_dict.keys())).union(rename_dict.values()))
    samples.sort()

# Import rules
include: join("rules", "common.smk")

if pipeline == 'cite':
    include: join("rules", "cite.smk")
if pipeline == "gex":
    include: join("rules", "gex.smk")
if pipeline == 'multi':
    include: join("rules", "multi.smk")
if pipeline == 'atac':
    include: join("rules", "atac.smk")
if pipeline == 'vdj':
    include: join("rules", "vdj.smk")
if pipeline == 'multiome':
    include: join("rules", "multiome.smk")

# Final output files of the pipeline (fully definited within the pipeline smk files)
rule all:
    input:
        pipeline_output
